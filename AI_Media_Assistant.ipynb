{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNz5uN6gygbDOj+Njwe8mIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaiazS/AI-Image-Generator-/blob/main/AI_Media_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "l-D_9TE8D-AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fee3658-b747-437c-c6c1-e16e37378aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.32.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing the required dependencies\n",
        "\n",
        "!pip install streamlit\n",
        "\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up Google Gemini API and API Key\n",
        "\n",
        "!pip install google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('Gemini_API_KEY')\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "available_models = genai.list_models()\n",
        "\n",
        "for model in available_models:\n",
        "\n",
        "  print(model.name)\n",
        "\n",
        "llm_model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
        "\n",
        "llm_model_input_prompt_response = llm_model.generate_content(\"Explain Multi-Modal AI\")\n",
        "\n",
        "print(llm_model_input_prompt_response.text)"
      ],
      "metadata": {
        "id": "ez7CWCzPFk39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc0d792a-85a7-4248-a275-c02e85641f65"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:09:00.712 200 GET /v1beta/models?pageSize=50&%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2092.51ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:09:14.052 200 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 13329.93ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-modal AI refers to artificial intelligence systems that can process and integrate information from multiple modalities.  A modality refers to a specific type of sensory input or data representation, such as text, images, audio, video, sensor data, and even things like touch or smell.  Instead of just analyzing one type of data in isolation, multi-modal AI models can combine these different modalities to gain a more comprehensive understanding and achieve better performance.\n",
            "\n",
            "Here's a breakdown of key aspects of multi-modal AI:\n",
            "\n",
            "* **Multiple Modalities:**  These are the different types of data the AI processes. Common examples include:\n",
            "    * **Text:**  Words, sentences, paragraphs, documents.\n",
            "    * **Images:**  Photographs, drawings, medical scans.\n",
            "    * **Audio:**  Speech, music, environmental sounds.\n",
            "    * **Video:**  Moving images with audio.\n",
            "    * **Sensor Data:**  Data from sensors like temperature, pressure, acceleration.\n",
            "\n",
            "* **Fusion:** This is the core concept of multi-modal AI. It's the process of combining information from different modalities.  There are several fusion methods:\n",
            "    * **Early Fusion:** Combining raw data from different modalities before processing.\n",
            "    * **Late Fusion:** Processing each modality separately and then combining the results.\n",
            "    * **Hybrid Fusion:**  A combination of early and late fusion.\n",
            "\n",
            "* **Benefits of Multi-Modal AI:**\n",
            "    * **Improved Accuracy and Performance:** By considering multiple sources of information, multi-modal AI can often achieve better results than single-modal models.\n",
            "    * **More Robustness:** Multi-modal models can be less susceptible to noise or missing data in one modality by relying on information from other modalities.\n",
            "    * **Better Understanding of Context:** Combining different modalities helps the AI understand the context and nuances of the information better.\n",
            "    * **Enabling New Applications:** Multi-modal AI opens up possibilities for new and innovative applications that were not possible with single-modal AI.\n",
            "\n",
            "* **Challenges of Multi-Modal AI:**\n",
            "    * **Data Integration:** Combining different data types can be complex due to varying formats, scales, and temporal aspects.\n",
            "    * **Computational Complexity:** Processing multiple modalities requires significant computational resources.\n",
            "    * **Model Development:** Designing and training effective multi-modal models can be challenging.\n",
            "    * **Data Scarcity:** Obtaining large, labeled datasets for multiple modalities can be difficult.\n",
            "\n",
            "\n",
            "* **Examples of Multi-Modal AI Applications:**\n",
            "    * **Image Captioning:**  Generating textual descriptions of images.\n",
            "    * **Visual Question Answering (VQA):** Answering questions about images.\n",
            "    * **Speech Recognition with Visual Cues:** Improving speech recognition by incorporating lip reading.\n",
            "    * **Sentiment Analysis from Video:** Analyzing video content to understand the emotional tone.\n",
            "    * **Medical Diagnosis:** Combining medical images, patient records, and sensor data for more accurate diagnoses.\n",
            "    * **Robotics:** Enabling robots to perceive and interact with the world using multiple sensors.\n",
            "\n",
            "\n",
            "In summary, multi-modal AI is a rapidly evolving field that holds immense potential for transforming various industries.  By leveraging the power of multiple modalities, these AI systems can achieve a more comprehensive and nuanced understanding of the world, leading to more intelligent and impactful applications.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the current .ipynb file to .py file\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92NFvGacFOq",
        "outputId": "dcbf429b-af93-499d-a7fd-5fa767b764ae"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile AI_Media_Assistant.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd9a9sOtdfRK",
        "outputId": "3ff907bb-a57f-4812-cfd2-7bbe99486125"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing AI_Media_Assistant.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "-XsmDB05sbPs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_ai_client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "5B0vMXtP0yw0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2vBNt35fG5TfQ0uYDbRwzoFEeDg_7HvUyhtbmV2AKbqdtHPiq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO2Dy3Rkiwh4",
        "outputId": "78ba425c-7dae-4350-ddd1-78f8658f22d0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok tunnels list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70zP33Ohnh9C",
        "outputId": "a700f077-7707-4431-9d99-ccfe5417f010"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok close tn_2vBQCoPVieJapVZvFQo1Tdgx2ug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEnugDmdnrxi",
        "outputId": "5d6a06d1-949a-456f-98fe-2f7a865b940a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok close tn_2vBQJnIhpCpuRTPyPPcjWvt7PWR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oJlLSiloGH8",
        "outputId": "22d7a5ed-517e-4995-f9e7-aae29fc0b6dd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining title for the Streamlit Application\n",
        "\n",
        "st.title(\"Synthetic Image Generator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjWAuuXru6Jq",
        "outputId": "1ccc01b9-338c-4123-9854-d9c78f20f7ae"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:09:50.901 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:50.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Enabling Users to enter prompts and Generate Images\n",
        "\n",
        "user_prompt = st.text_input(\"Please provide the content on based you want to generate the image\")\n",
        "\n",
        "if st.button(\"Manifest Image\"):\n",
        "\n",
        "  if not user_prompt:\n",
        "\n",
        "    st.warning(\"Please provide more information regarding the image you want to manifest!\")\n",
        "\n",
        "  else:\n",
        "\n",
        "      try:\n",
        "\n",
        "          with st.spinner(\"Manifesting Image....\"):\n",
        "\n",
        "            image_response = gen_ai_client.models.generate_content(\n",
        "\n",
        "\n",
        "                                                                 model = \"gemini-2.0-flash-exp-image-generation\",\n",
        "\n",
        "                                                                 contents = user_prompt,\n",
        "\n",
        "                                                                 config = type.GenerateContentConfig(response_modalities = ['Text','Image'])\n",
        "\n",
        "\n",
        "          )\n",
        "\n",
        "#Enabling users to display the Images post Generation\n",
        "\n",
        "          st.subheader(\"Manifested Image\")\n",
        "\n",
        "          for part in image_response.candidates[0].content.parts:\n",
        "\n",
        "            if part.text is not None:\n",
        "\n",
        "              st.write(part.text)\n",
        "\n",
        "            elif part.inline_data is not None:\n",
        "\n",
        "                manifested_image = Image.open(BytesIO((part.inline_data.data)))\n",
        "\n",
        "                st.image(manifested_image)\n",
        "\n",
        "      except Exception as e:\n",
        "\n",
        "          st.error(\"Oops we will fix it soon, please try again later!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3D4D3LyvR68",
        "outputId": "91933a2b-7240-424d-97c2-db023c291eb6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:09:56.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.640 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:09:56.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Captions for Images**"
      ],
      "metadata": {
        "id": "YePC2IwESjT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.title(\"Image Caption Generator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-pcCL0_SoMd",
        "outputId": "ea47dfc6-088f-4445-810f-51661a6ac751"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:10:01.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:01.658 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload the file to be captioned\n",
        "\n",
        "pre_captioned_image = st.file_uploader(\"Please upload the image to be captioned\", type = ['png', 'jpg', 'jpeg'])\n",
        "\n",
        "if pre_captioned_image is not None:\n",
        "\n",
        "  cap_image = Image.open(pre_captioned_image)\n",
        "\n",
        "  st.image(cap_image, caption = \"Uploaded_Image\")\n",
        "\n",
        "  if st.button(\"Generate Caption\"):\n",
        "\n",
        "      try:\n",
        "\n",
        "        with st.spinner(\"Generating Caption...\"):\n",
        "\n",
        "          image_caption_response = gen_ai_client.models.generate_content(\n",
        "\n",
        "                                                                 model = \"gemini-2.0-flash\",\n",
        "\n",
        "                                                                 contents = [\"Tell me about this image\", cap_image]\n",
        "        )\n",
        "\n",
        "        st.subheader(\"Generated Caption:\")\n",
        "\n",
        "        st.write(image_caption_response.text)\n",
        "\n",
        "      except Exception as e:\n",
        "\n",
        "        st.error(\"Please try later!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TnqDi4iS13W",
        "outputId": "df5a6d58-03fc-42a9-c9df-ba914b0ee8d9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:10:08.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:08.037 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:08.038 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:08.038 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:08.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Captions/Summarization for Videos**"
      ],
      "metadata": {
        "id": "eIXEBGVLYxyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.title(\"Video Summary Generator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6Wq9kjY36y",
        "outputId": "1eb18beb-3e2c-4392-efc7-c854b88f6bae"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:10:11.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:11.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_url = st.text_input(\"Please provide the link to the video you want to summarize..\")\n",
        "\n",
        "if st.button(\"Summarize video\"):\n",
        "\n",
        "   if not video_url:\n",
        "\n",
        "      st.warning(\"Please provide a valid video link\")\n",
        "\n",
        "   else:\n",
        "\n",
        "      try:\n",
        "\n",
        "        with st.spinner(\"Summarizing Video...\"):\n",
        "\n",
        "          video_summary_response = gen_ai_client.models.generate_content(\n",
        "\n",
        "                                                                         model = \"models/gemini-2.0-flash\",\n",
        "\n",
        "                                                                         contents = types.Content(parts = [types.Part(text = \"Please summarize the contents of this video\"),\n",
        "\n",
        "                                                                                                           types.Part(file_data = types.FileData(file_url = video_url))])\n",
        "          )\n",
        "\n",
        "        st.subheader(\"Video Summary:\")\n",
        "\n",
        "        st.write(video_summary_response.text)\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "\n",
        "        st.error(\"We are working on the fix, please make sure to try again later!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "232fUAFcZCP0",
        "outputId": "ce182823-e506-42cc-8377-86baef7b22df"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 22:10:13.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.648 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.655 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 22:10:13.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the Streamlit Application\n",
        "\n",
        "%pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ngrok.set_auth_token(userdata.get('ngrok_auth_token'))\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "active_tunnels = ngrok.get_tunnels()\n",
        "\n",
        "for tunnel in active_tunnels:\n",
        "\n",
        "  print(f\"Closing existing tunnel : {tunnel.public_url}\")\n",
        "  ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(f\"Your App is running on url : {public_url}\")\n",
        "\n",
        "!streamlit run \"AI_Media_Assistant.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EEEIZWUdx19",
        "outputId": "d2ef7f5b-6f92-4294-aa87-559ca74df323"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Your App is running on url : NgrokTunnel: \"https://0df6-35-227-70-233.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.70.233:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JzItbQ0QhRxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN6XDeECEV6SXxUVa2oRzrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaiazS/AI-Image-Generator-/blob/main/AI_Image_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l-D_9TE8D-AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b73f222-361b-4c54-c5e7-3301ede3ed9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.32.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing the required dependencies\n",
        "\n",
        "!pip install streamlit\n",
        "\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up Google Gemini API and API Key\n",
        "\n",
        "!pip install google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('Gemini_API_KEY')\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "available_models = genai.list_models()\n",
        "\n",
        "for model in available_models:\n",
        "\n",
        "  print(model.name)\n",
        "\n",
        "llm_model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
        "\n",
        "llm_model_input_prompt_response = llm_model.generate_content(\"Explain Multi-Modal AI\")\n",
        "\n",
        "print(llm_model_input_prompt_response.text)"
      ],
      "metadata": {
        "id": "ez7CWCzPFk39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bac13c67-4717-429a-b443-58e2d3a5248b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 20:31:46.517 200 GET /v1beta/models?pageSize=50&%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2379.58ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "Multi-modal AI refers to artificial intelligence systems that can process and integrate information from multiple modalities.  A modality refers to a type of data or input, such as text, images, audio, video, sensor data, and even other modalities like depth maps or thermal images.  Instead of working with just one type of data (like text in traditional natural language processing), multi-modal AI models are designed to handle and understand the complex relationships *between* these different data types.\n",
            "\n",
            "Here's a breakdown of key aspects of multi-modal AI:\n",
            "\n",
            "* **Multiple Input Modalities:** This is the core concept.  The system can accept different types of data as input.  Imagine an AI that takes both an image and a text caption as input.\n",
            "\n",
            "* **Joint Representation Learning:**  Multi-modal AI models learn a shared representation that captures the information from all the input modalities. This joint representation allows the model to understand the connections and relationships between the different data types. For example, it might learn that a picture of a cat correlates with the word \"cat\" in a caption.\n",
            "\n",
            "* **Enhanced Understanding and Performance:**  By combining information from multiple modalities, these AI systems can achieve a more nuanced and comprehensive understanding of the world. They can often perform tasks more effectively than single-modality models.  For instance, a model that analyzes both the audio and video of a person speaking can better understand their emotions than a model that only analyzes the audio.\n",
            "\n",
            "* **Diverse Applications:** Multi-modal AI has a wide range of applications across various fields, including:\n",
            "    * **Image Captioning:** Generating textual descriptions of images.\n",
            "    * **Visual Question Answering (VQA):** Answering questions about images.\n",
            "    * **Audio-Visual Speech Recognition:**  Improving speech recognition by incorporating visual information about the speaker's lip movements.\n",
            "    * **Multi-Modal Sentiment Analysis:**  Analyzing text, audio, and video to determine the sentiment expressed by a person.\n",
            "    * **Robotics:**  Enabling robots to perceive and interact with the world more effectively using multiple sensors (vision, touch, etc.).\n",
            "    * **Healthcare:**  Analyzing medical images and patient records to improve diagnosis and treatment.\n",
            "\n",
            "\n",
            "**Challenges in Multi-modal AI:**\n",
            "\n",
            "While promising, multi-modal AI also faces several challenges:\n",
            "\n",
            "* **Data Fusion:** Effectively combining data from different modalities can be complex, as they often have different structures and scales.\n",
            "* **Computational Cost:** Training multi-modal models can be computationally expensive, especially with large datasets and complex architectures.\n",
            "* **Data Scarcity:**  Obtaining large, high-quality datasets with aligned multi-modal data can be difficult.\n",
            "* **Interpretability:**  Understanding how multi-modal models arrive at their decisions can be challenging, especially with complex joint representations.\n",
            "\n",
            "\n",
            "Despite these challenges, multi-modal AI is a rapidly evolving field with significant potential to transform the way we interact with machines and understand the world around us.  As research progresses and datasets improve, we can expect even more innovative and powerful applications to emerge.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 20:31:59.600 200 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 13071.21ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the current .ipynb file to .py file\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92NFvGacFOq",
        "outputId": "a62c51f9-9501-4fb0-8dfb-2e1f7d019556"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile AI_Image_Generator.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd9a9sOtdfRK",
        "outputId": "f7746373-5ae1-432a-864b-500260a6c126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing AI_Image_Generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "-XsmDB05sbPs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_ai_client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "5B0vMXtP0yw0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2vBNt35fG5TfQ0uYDbRwzoFEeDg_7HvUyhtbmV2AKbqdtHPiq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO2Dy3Rkiwh4",
        "outputId": "27d18d2a-b0f8-472f-a986-e95d798a656f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok tunnels list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70zP33Ohnh9C",
        "outputId": "6675fc01-d954-4c21-a37b-e304e3e104ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok close tn_2vBQCoPVieJapVZvFQo1Tdgx2ug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEnugDmdnrxi",
        "outputId": "2ce32599-a987-4faa-bda2-8f0aa4da2e11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok close tn_2vBQJnIhpCpuRTPyPPcjWvt7PWR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oJlLSiloGH8",
        "outputId": "4386b443-9f95-40db-d7be-ae02bfa4d9a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining title for the Streamlit Application\n",
        "\n",
        "st.title(\"Synthetic Image Generator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjWAuuXru6Jq",
        "outputId": "e6c99724-c04a-48b4-86a2-c8b3c243615f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 18:49:12.453 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 18:49:12.731 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-02 18:49:12.752 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Enabling Users to enter prompts and Generate Images\n",
        "\n",
        "user_prompt = st.text_input(\"Please provide the content on based you want to generate the image\")\n",
        "\n",
        "if st.button(\"Manifest Image\"):\n",
        "\n",
        "  if not user_prompt:\n",
        "\n",
        "    st.warning(\"Please provide more information regarding the image you want to manifest!\")\n",
        "\n",
        "  else:\n",
        "\n",
        "      try:\n",
        "\n",
        "          with st.spinner(\"Manifesting Image....\"):\n",
        "\n",
        "            image_response = gen_ai_client.models.generate_content(\n",
        "\n",
        "\n",
        "                                                                 model = \"gemini-2.0-flash-exp-image-generation\",\n",
        "\n",
        "                                                                 contents = user_prompt,\n",
        "\n",
        "                                                                 config = type.GenerateContentConfig(response_modalities = ['Text','Image'])\n",
        "\n",
        "\n",
        "          )\n",
        "\n",
        "#Enabling users to display the Images post Generation\n",
        "\n",
        "          st.subheader(\"Manifested Image\")\n",
        "\n",
        "          for part in image_response.candidates[0].content.parts:\n",
        "\n",
        "            if part.text is not None:\n",
        "\n",
        "              st.write(part.text)\n",
        "\n",
        "            elif part.inline_data is not None:\n",
        "\n",
        "                manifested_image = Image.open(BytesIO((part.inline_data.data)))\n",
        "\n",
        "                st.image(manifested_image)\n",
        "\n",
        "      except Exception as e:\n",
        "\n",
        "          st.error(\"Oops we will fix it soon, please try again later!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3D4D3LyvR68",
        "outputId": "ec3a795f-d309-4894-f9ed-ce4547aec7ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-02 20:23:21.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-02 20:23:21.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the Streamlit Application\n",
        "\n",
        "%pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ngrok.set_auth_token(userdata.get('ngrok_auth_token'))\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(f\"Your App is running on url : {public_url}\")\n",
        "\n",
        "!streamlit run \"AI_Image_Generator.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sONscWi9KpVi",
        "outputId": "95914fc4-1be9-4a52-bc95-c3c9205454be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Your App is running on url : NgrokTunnel: \"https://261e-35-227-70-233.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.70.233:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqIHuuR2LpYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}